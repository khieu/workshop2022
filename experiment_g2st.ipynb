{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "from sklearn import svm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./g2st.txt') as f:\n",
    "    data = [l for l in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapoints = [point.split(':') for point in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [int(point[0]) for point in datapoints]\n",
    "input_long = [json.loads(point[3]) for point in datapoints]\n",
    "input_short = [json.loads(point[1]) for point in datapoints]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pd = pd.DataFrame(input_short)\n",
    "long_test_pd = pd.DataFrame(input_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# long input does not have any NaN\n",
    "# short input has some NaN in the last column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1,\n",
       "        1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0,\n",
       "        1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "        1, 1, 0, 1], device='cuda:0')"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.count_nonzero(test_pd.isna()[6])\n",
    "test_pd[6] = test_pd[6].fillna(0)\n",
    "# normalized_test_pd = preprocessing.normalize(test_pd)\n",
    "# normalized_test_pd = pd.DataFrame(normalized_test_pd, columns=test_pd.columns)\n",
    "normalized_test_pd = preprocessing.normalize(long_test_pd)\n",
    "normalized_test_pd = pd.DataFrame(normalized_test_pd, columns=long_test_pd.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = normalized_test_pd.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolynomialDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.input_data = X\n",
    "        self.labels = Y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_data[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "train_dataset = PolynomialDataset(X_train, y_train)\n",
    "test_dataset = PolynomialDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800000, 7)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "n_iters = 160000\n",
    "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class FeedforwardNeuralNetModel(nn.Module):\n",
    "#     def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "#         super(FeedforwardNeuralNetModel, self).__init__()\n",
    "        \n",
    "#         self.fc1 = nn.Linear(input_dim, hidden_dim) \n",
    "#         self.sigmoid = nn.Sigmoid()\n",
    "#         self.fc2 = nn.Linear(hidden_dim, output_dim)  \n",
    "\n",
    "#     def forward(self, x):\n",
    "#         out = self.fc1(x)\n",
    "#         out = self.sigmoid(out)\n",
    "#         out = self.fc2(out)\n",
    "#         return out\n",
    "class FeedforwardNeuralNetModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(FeedforwardNeuralNetModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim) \n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc4 = nn.Linear(hidden_dim, output_dim)  \n",
    "        \n",
    "        \n",
    "        # Define batch norm\n",
    "        self.batch_norm = nn.BatchNorm1d(hidden_dim)\n",
    "\n",
    "        # Define proportion or neurons to dropout\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        #out = self.dropout(out)\n",
    "        #out = self.batch_norm(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        #out = self.dropout(out)\n",
    "        #out = self.batch_norm(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.fc3(out)\n",
    "        #out = self.dropout(out)\n",
    "        #out = self.batch_norm(out)\n",
    "        out = self.relu3(out)\n",
    "        out = self.fc4(out)\n",
    "        return out\n",
    "    \n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, batch_size, n_inputs, n_neurons):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.rnn = nn.RNNCell(n_inputs, n_neurons)\n",
    "        self.hx = torch.randn(batch_size, n_neurons) # initialize hidden state\n",
    "        \n",
    "    def forward(self, X):\n",
    "        output = []\n",
    "\n",
    "        # for each time step\n",
    "        for i in range(2):\n",
    "            self.hx = self.rnn(X[i], self.hx)\n",
    "            output.append(self.hx)\n",
    "        \n",
    "        return output, self.hx\n",
    "\n",
    "class CovNet(nn.Module):   \n",
    "    def __init__(self):\n",
    "        super(CovNet, self).__init__()\n",
    "\n",
    "        self.cnn_layers = nn.Sequential(\n",
    "            # Defining a 2D convolution layer\n",
    "            nn.Conv2d(1, 4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            # Defining another 2D convolution layer\n",
    "            nn.Conv2d(4, 4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        self.linear_layers = nn.Sequential(\n",
    "            nn.Linear(4 * 7 * 7, 2)\n",
    "        )\n",
    "\n",
    "    # Defining the forward pass    \n",
    "    def forward(self, x):\n",
    "        x = self.cnn_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear_layers(x)\n",
    "        return x\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 7\n",
    "hidden_dim = 100\n",
    "output_dim = 2\n",
    "\n",
    "model = FeedforwardNeuralNetModel(input_dim, hidden_dim, output_dim)\n",
    "learning_rate = 0.2\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate) \n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch2/hle/py3_env/lib/python3.7/site-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"\n",
      "/scratch2/hle/py3_env/lib/python3.7/site-packages/ipykernel_launcher.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500. Loss: 0.6656690239906311. Accuracy: 66.8205\n",
      "Iteration: 1000. Loss: 0.5926105976104736. Accuracy: 69.6605\n",
      "Iteration: 1500. Loss: 0.6073428988456726. Accuracy: 71.8865\n",
      "Iteration: 2000. Loss: 0.5559986233711243. Accuracy: 70.698\n",
      "Iteration: 2500. Loss: 0.5241569876670837. Accuracy: 73.3515\n",
      "Iteration: 3000. Loss: 0.4888678789138794. Accuracy: 74.4215\n",
      "Iteration: 3500. Loss: 0.4747890830039978. Accuracy: 74.5055\n",
      "Iteration: 4000. Loss: 0.4500879645347595. Accuracy: 74.9905\n",
      "Iteration: 4500. Loss: 0.45948997139930725. Accuracy: 74.79\n",
      "Iteration: 5000. Loss: 0.50010085105896. Accuracy: 74.852\n",
      "Iteration: 5500. Loss: 0.49843043088912964. Accuracy: 75.0315\n",
      "Iteration: 6000. Loss: 0.5296173095703125. Accuracy: 76.3845\n",
      "Iteration: 6500. Loss: 0.501549482345581. Accuracy: 76.1815\n",
      "Iteration: 7000. Loss: 0.49102818965911865. Accuracy: 75.9955\n",
      "Iteration: 7500. Loss: 0.5147882103919983. Accuracy: 76.179\n",
      "Iteration: 8000. Loss: 0.49469563364982605. Accuracy: 76.9395\n",
      "Iteration: 8500. Loss: 0.5069343447685242. Accuracy: 76.8065\n",
      "Iteration: 9000. Loss: 0.4058859944343567. Accuracy: 76.9775\n",
      "Iteration: 9500. Loss: 0.45684361457824707. Accuracy: 76.484\n",
      "Iteration: 10000. Loss: 0.41795989871025085. Accuracy: 77.2815\n",
      "Iteration: 10500. Loss: 0.4303881824016571. Accuracy: 77.7785\n",
      "Iteration: 11000. Loss: 0.4862598180770874. Accuracy: 76.649\n",
      "Iteration: 11500. Loss: 0.4444245994091034. Accuracy: 77.255\n",
      "Iteration: 12000. Loss: 0.458232581615448. Accuracy: 77.6565\n",
      "Iteration: 12500. Loss: 0.40495991706848145. Accuracy: 75.6675\n",
      "Iteration: 13000. Loss: 0.5092995762825012. Accuracy: 77.829\n",
      "Iteration: 13500. Loss: 0.40786612033843994. Accuracy: 78.2445\n",
      "Iteration: 14000. Loss: 0.5105611085891724. Accuracy: 78.3455\n",
      "Iteration: 14500. Loss: 0.4483356177806854. Accuracy: 77.385\n",
      "Iteration: 15000. Loss: 0.5388157963752747. Accuracy: 77.504\n",
      "Iteration: 15500. Loss: 0.42220208048820496. Accuracy: 78.3175\n",
      "Iteration: 16000. Loss: 0.5295446515083313. Accuracy: 78.719\n",
      "Iteration: 16500. Loss: 0.3895711600780487. Accuracy: 78.669\n",
      "Iteration: 17000. Loss: 0.45822855830192566. Accuracy: 78.372\n",
      "Iteration: 17500. Loss: 0.369189977645874. Accuracy: 78.852\n",
      "Iteration: 18000. Loss: 0.49145206809043884. Accuracy: 78.4025\n",
      "Iteration: 18500. Loss: 0.4670989215373993. Accuracy: 78.2755\n",
      "Iteration: 19000. Loss: 0.5245867967605591. Accuracy: 79.028\n",
      "Iteration: 19500. Loss: 0.4556763768196106. Accuracy: 78.7245\n",
      "Iteration: 20000. Loss: 0.4944438934326172. Accuracy: 78.6485\n",
      "Iteration: 20500. Loss: 0.4420136511325836. Accuracy: 79.557\n",
      "Iteration: 21000. Loss: 0.386769562959671. Accuracy: 77.9185\n",
      "Iteration: 21500. Loss: 0.39451390504837036. Accuracy: 78.6965\n",
      "Iteration: 22000. Loss: 0.3632950484752655. Accuracy: 79.217\n",
      "Iteration: 22500. Loss: 0.4569578468799591. Accuracy: 79.221\n",
      "Iteration: 23000. Loss: 0.5000653862953186. Accuracy: 78.615\n",
      "Iteration: 23500. Loss: 0.5044851303100586. Accuracy: 79.019\n",
      "Iteration: 24000. Loss: 0.4200930893421173. Accuracy: 78.968\n",
      "Iteration: 24500. Loss: 0.5333026647567749. Accuracy: 78.6705\n",
      "Iteration: 25000. Loss: 0.4607369601726532. Accuracy: 78.6065\n",
      "Iteration: 25500. Loss: 0.4115280508995056. Accuracy: 79.1975\n",
      "Iteration: 26000. Loss: 0.49048903584480286. Accuracy: 79.6345\n",
      "Iteration: 26500. Loss: 0.41794708371162415. Accuracy: 79.148\n",
      "Iteration: 27000. Loss: 0.5070575475692749. Accuracy: 79.809\n",
      "Iteration: 27500. Loss: 0.4093254506587982. Accuracy: 79.57\n",
      "Iteration: 28000. Loss: 0.36995646357536316. Accuracy: 79.472\n",
      "Iteration: 28500. Loss: 0.5252070426940918. Accuracy: 79.471\n",
      "Iteration: 29000. Loss: 0.4320931136608124. Accuracy: 79.0945\n",
      "Iteration: 29500. Loss: 0.47115328907966614. Accuracy: 79.377\n",
      "Iteration: 30000. Loss: 0.3346613347530365. Accuracy: 79.6795\n",
      "Iteration: 30500. Loss: 0.4654863774776459. Accuracy: 79.4565\n",
      "Iteration: 31000. Loss: 0.41114017367362976. Accuracy: 79.9275\n",
      "Iteration: 31500. Loss: 0.47230231761932373. Accuracy: 79.3465\n",
      "Iteration: 32000. Loss: 0.4192870855331421. Accuracy: 80.251\n",
      "Iteration: 32500. Loss: 0.48290520906448364. Accuracy: 79.8055\n",
      "Iteration: 33000. Loss: 0.4338397681713104. Accuracy: 78.482\n",
      "Iteration: 33500. Loss: 0.40052783489227295. Accuracy: 79.651\n",
      "Iteration: 34000. Loss: 0.45128723978996277. Accuracy: 78.275\n",
      "Iteration: 34500. Loss: 0.4557022750377655. Accuracy: 79.086\n",
      "Iteration: 35000. Loss: 0.5155047178268433. Accuracy: 79.257\n",
      "Iteration: 35500. Loss: 0.45309242606163025. Accuracy: 79.935\n",
      "Iteration: 36000. Loss: 0.4265652000904083. Accuracy: 79.494\n",
      "Iteration: 36500. Loss: 0.45983752608299255. Accuracy: 79.1745\n",
      "Iteration: 37000. Loss: 0.4032661020755768. Accuracy: 77.687\n",
      "Iteration: 37500. Loss: 0.5975789427757263. Accuracy: 79.9505\n",
      "Iteration: 38000. Loss: 0.40257278084754944. Accuracy: 79.2835\n",
      "Iteration: 38500. Loss: 0.4626518189907074. Accuracy: 79.7595\n",
      "Iteration: 39000. Loss: 0.5046985745429993. Accuracy: 79.4495\n",
      "Iteration: 39500. Loss: 0.4702546000480652. Accuracy: 79.774\n",
      "Iteration: 40000. Loss: 0.4747823476791382. Accuracy: 79.533\n",
      "Iteration: 40500. Loss: 0.44556114077568054. Accuracy: 79.5755\n",
      "Iteration: 41000. Loss: 0.40457552671432495. Accuracy: 80.4735\n",
      "Iteration: 41500. Loss: 0.4536159038543701. Accuracy: 80.0215\n",
      "Iteration: 42000. Loss: 0.4267920255661011. Accuracy: 79.881\n",
      "Iteration: 42500. Loss: 0.38294053077697754. Accuracy: 80.1185\n",
      "Iteration: 43000. Loss: 0.49279823899269104. Accuracy: 79.235\n",
      "Iteration: 43500. Loss: 0.4371320307254791. Accuracy: 79.852\n",
      "Iteration: 44000. Loss: 0.43052569031715393. Accuracy: 79.637\n",
      "Iteration: 44500. Loss: 0.4220694601535797. Accuracy: 80.1295\n",
      "Iteration: 45000. Loss: 0.440237820148468. Accuracy: 79.7825\n",
      "Iteration: 45500. Loss: 0.4623851478099823. Accuracy: 80.075\n",
      "Iteration: 46000. Loss: 0.3898259997367859. Accuracy: 80.1325\n",
      "Iteration: 46500. Loss: 0.42748692631721497. Accuracy: 80.0685\n",
      "Iteration: 47000. Loss: 0.46125638484954834. Accuracy: 80.2535\n",
      "Iteration: 47500. Loss: 0.38713014125823975. Accuracy: 80.3485\n",
      "Iteration: 48000. Loss: 0.41052353382110596. Accuracy: 80.3145\n",
      "Iteration: 48500. Loss: 0.5071478486061096. Accuracy: 78.1695\n",
      "Iteration: 49000. Loss: 0.4779495894908905. Accuracy: 80.221\n",
      "Iteration: 49500. Loss: 0.5453100800514221. Accuracy: 79.7675\n",
      "Iteration: 50000. Loss: 0.4040539264678955. Accuracy: 80.2565\n",
      "Iteration: 50500. Loss: 0.48571884632110596. Accuracy: 80.0265\n",
      "Iteration: 51000. Loss: 0.3823768198490143. Accuracy: 80.127\n",
      "Iteration: 51500. Loss: 0.39179283380508423. Accuracy: 80.2745\n",
      "Iteration: 52000. Loss: 0.4161027669906616. Accuracy: 79.241\n",
      "Iteration: 52500. Loss: 0.47811180353164673. Accuracy: 80.2725\n",
      "Iteration: 53000. Loss: 0.3406844437122345. Accuracy: 80.2865\n",
      "Iteration: 53500. Loss: 0.3874383866786957. Accuracy: 80.47\n",
      "Iteration: 54000. Loss: 0.4453939199447632. Accuracy: 80.326\n",
      "Iteration: 54500. Loss: 0.4573954641819. Accuracy: 80.432\n",
      "Iteration: 55000. Loss: 0.5188313126564026. Accuracy: 79.904\n",
      "Iteration: 55500. Loss: 0.445165753364563. Accuracy: 80.3215\n",
      "Iteration: 56000. Loss: 0.39031773805618286. Accuracy: 80.42\n",
      "Iteration: 56500. Loss: 0.3348872661590576. Accuracy: 80.431\n",
      "Iteration: 57000. Loss: 0.4557826519012451. Accuracy: 79.9185\n",
      "Iteration: 57500. Loss: 0.553871214389801. Accuracy: 79.7895\n",
      "Iteration: 58000. Loss: 0.4202255308628082. Accuracy: 79.937\n",
      "Iteration: 58500. Loss: 0.3879155218601227. Accuracy: 80.102\n",
      "Iteration: 59000. Loss: 0.4396972358226776. Accuracy: 80.413\n",
      "Iteration: 59500. Loss: 0.5642368793487549. Accuracy: 80.3655\n",
      "Iteration: 60000. Loss: 0.43134522438049316. Accuracy: 80.3745\n",
      "Iteration: 60500. Loss: 0.4475126266479492. Accuracy: 80.4275\n",
      "Iteration: 61000. Loss: 0.49466443061828613. Accuracy: 80.3385\n",
      "Iteration: 61500. Loss: 0.4047967493534088. Accuracy: 80.075\n",
      "Iteration: 62000. Loss: 0.5094326138496399. Accuracy: 80.429\n",
      "Iteration: 62500. Loss: 0.3884657025337219. Accuracy: 80.4635\n",
      "Iteration: 63000. Loss: 0.4366154372692108. Accuracy: 80.526\n",
      "Iteration: 63500. Loss: 0.43249741196632385. Accuracy: 80.205\n",
      "Iteration: 64000. Loss: 0.4107116460800171. Accuracy: 80.564\n",
      "Iteration: 64500. Loss: 0.42328545451164246. Accuracy: 80.5835\n",
      "Iteration: 65000. Loss: 0.4913678765296936. Accuracy: 80.53\n",
      "Iteration: 65500. Loss: 0.41534939408302307. Accuracy: 80.0645\n",
      "Iteration: 66000. Loss: 0.41080009937286377. Accuracy: 80.559\n",
      "Iteration: 66500. Loss: 0.5137287378311157. Accuracy: 80.6155\n",
      "Iteration: 67000. Loss: 0.3669852018356323. Accuracy: 80.433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 67500. Loss: 0.42426803708076477. Accuracy: 80.398\n",
      "Iteration: 68000. Loss: 0.491338849067688. Accuracy: 80.201\n",
      "Iteration: 68500. Loss: 0.3471423089504242. Accuracy: 80.366\n",
      "Iteration: 69000. Loss: 0.44140616059303284. Accuracy: 80.275\n",
      "Iteration: 69500. Loss: 0.4585306942462921. Accuracy: 80.138\n",
      "Iteration: 70000. Loss: 0.4553932845592499. Accuracy: 80.114\n",
      "Iteration: 70500. Loss: 0.34115487337112427. Accuracy: 80.555\n",
      "Iteration: 71000. Loss: 0.4786321222782135. Accuracy: 80.316\n",
      "Iteration: 71500. Loss: 0.4173159897327423. Accuracy: 80.721\n",
      "Iteration: 72000. Loss: 0.41921550035476685. Accuracy: 80.488\n",
      "Iteration: 72500. Loss: 0.4515882730484009. Accuracy: 80.623\n",
      "Iteration: 73000. Loss: 0.42797496914863586. Accuracy: 80.834\n",
      "Iteration: 73500. Loss: 0.44930049777030945. Accuracy: 80.4655\n",
      "Iteration: 74000. Loss: 0.3240950107574463. Accuracy: 80.5695\n",
      "Iteration: 74500. Loss: 0.327170193195343. Accuracy: 80.431\n",
      "Iteration: 75000. Loss: 0.3896833062171936. Accuracy: 80.554\n",
      "Iteration: 75500. Loss: 0.4657455086708069. Accuracy: 80.546\n",
      "Iteration: 76000. Loss: 0.4543078541755676. Accuracy: 80.3695\n",
      "Iteration: 76500. Loss: 0.4608522653579712. Accuracy: 80.5095\n",
      "Iteration: 77000. Loss: 0.4246763586997986. Accuracy: 80.662\n",
      "Iteration: 77500. Loss: 0.4518672823905945. Accuracy: 80.4565\n",
      "Iteration: 78000. Loss: 0.47432276606559753. Accuracy: 80.6895\n",
      "Iteration: 78500. Loss: 0.4061402380466461. Accuracy: 80.3055\n",
      "Iteration: 79000. Loss: 0.4512626528739929. Accuracy: 80.673\n",
      "Iteration: 79500. Loss: 0.49345311522483826. Accuracy: 80.458\n",
      "Iteration: 80000. Loss: 0.4462355077266693. Accuracy: 80.3045\n",
      "Iteration: 80500. Loss: 0.4521482586860657. Accuracy: 80.5305\n",
      "Iteration: 81000. Loss: 0.5673394203186035. Accuracy: 80.0675\n",
      "Iteration: 81500. Loss: 0.5237216353416443. Accuracy: 80.7435\n",
      "Iteration: 82000. Loss: 0.37578096985816956. Accuracy: 80.6615\n",
      "Iteration: 82500. Loss: 0.3467521667480469. Accuracy: 79.546\n",
      "Iteration: 83000. Loss: 0.39843595027923584. Accuracy: 80.5545\n",
      "Iteration: 83500. Loss: 0.40198567509651184. Accuracy: 80.1395\n",
      "Iteration: 84000. Loss: 0.4348403215408325. Accuracy: 80.376\n",
      "Iteration: 84500. Loss: 0.3939715623855591. Accuracy: 80.7065\n",
      "Iteration: 85000. Loss: 0.3694625794887543. Accuracy: 80.593\n",
      "Iteration: 85500. Loss: 0.4924885034561157. Accuracy: 80.6875\n",
      "Iteration: 86000. Loss: 0.37360167503356934. Accuracy: 80.68\n",
      "Iteration: 86500. Loss: 0.365685373544693. Accuracy: 80.784\n",
      "Iteration: 87000. Loss: 0.4685012698173523. Accuracy: 80.639\n",
      "Iteration: 87500. Loss: 0.4755152761936188. Accuracy: 79.7205\n",
      "Iteration: 88000. Loss: 0.4141422510147095. Accuracy: 80.8235\n",
      "Iteration: 88500. Loss: 0.4330522418022156. Accuracy: 80.724\n",
      "Iteration: 89000. Loss: 0.38970592617988586. Accuracy: 80.7085\n",
      "Iteration: 89500. Loss: 0.4033536911010742. Accuracy: 80.4605\n",
      "Iteration: 90000. Loss: 0.45040228962898254. Accuracy: 79.5445\n",
      "Iteration: 90500. Loss: 0.42220965027809143. Accuracy: 80.801\n",
      "Iteration: 91000. Loss: 0.36600151658058167. Accuracy: 80.2115\n",
      "Iteration: 91500. Loss: 0.3627208471298218. Accuracy: 80.8505\n",
      "Iteration: 92000. Loss: 0.4292769134044647. Accuracy: 80.1455\n",
      "Iteration: 92500. Loss: 0.4442819356918335. Accuracy: 80.9415\n",
      "Iteration: 93000. Loss: 0.35601016879081726. Accuracy: 80.7355\n",
      "Iteration: 93500. Loss: 0.4190801978111267. Accuracy: 80.872\n",
      "Iteration: 94000. Loss: 0.40821945667266846. Accuracy: 80.717\n",
      "Iteration: 94500. Loss: 0.434307336807251. Accuracy: 80.8655\n",
      "Iteration: 95000. Loss: 0.4450840353965759. Accuracy: 80.937\n",
      "Iteration: 95500. Loss: 0.3627982437610626. Accuracy: 80.94\n",
      "Iteration: 96000. Loss: 0.42635205388069153. Accuracy: 80.4055\n",
      "Iteration: 96500. Loss: 0.5238993167877197. Accuracy: 80.4405\n",
      "Iteration: 97000. Loss: 0.38662564754486084. Accuracy: 80.6325\n",
      "Iteration: 97500. Loss: 0.3421207070350647. Accuracy: 80.694\n",
      "Iteration: 98000. Loss: 0.47021621465682983. Accuracy: 80.4605\n",
      "Iteration: 98500. Loss: 0.4207793176174164. Accuracy: 80.6615\n",
      "Iteration: 99000. Loss: 0.41864117980003357. Accuracy: 80.902\n",
      "Iteration: 99500. Loss: 0.44105491042137146. Accuracy: 80.6035\n",
      "Iteration: 100000. Loss: 0.4259077310562134. Accuracy: 80.9255\n",
      "Iteration: 100500. Loss: 0.4926559031009674. Accuracy: 80.5295\n",
      "Iteration: 101000. Loss: 0.4218188524246216. Accuracy: 80.9455\n",
      "Iteration: 101500. Loss: 0.364996075630188. Accuracy: 80.794\n",
      "Iteration: 102000. Loss: 0.4487766921520233. Accuracy: 80.362\n",
      "Iteration: 102500. Loss: 0.4604122042655945. Accuracy: 80.9585\n",
      "Iteration: 103000. Loss: 0.4386659264564514. Accuracy: 80.966\n",
      "Iteration: 103500. Loss: 0.4598587155342102. Accuracy: 80.927\n",
      "Iteration: 104000. Loss: 0.35053855180740356. Accuracy: 80.921\n",
      "Iteration: 104500. Loss: 0.460077166557312. Accuracy: 79.7695\n",
      "Iteration: 105000. Loss: 0.35510051250457764. Accuracy: 80.649\n",
      "Iteration: 105500. Loss: 0.41434863209724426. Accuracy: 81.0865\n",
      "Iteration: 106000. Loss: 0.33059555292129517. Accuracy: 81.0455\n",
      "Iteration: 106500. Loss: 0.4688777029514313. Accuracy: 80.8085\n",
      "Iteration: 107000. Loss: 0.42907389998435974. Accuracy: 81.18\n",
      "Iteration: 107500. Loss: 0.3629223704338074. Accuracy: 81.147\n",
      "Iteration: 108000. Loss: 0.35548636317253113. Accuracy: 80.789\n",
      "Iteration: 108500. Loss: 0.385946124792099. Accuracy: 80.662\n",
      "Iteration: 109000. Loss: 0.4305174648761749. Accuracy: 80.9245\n",
      "Iteration: 109500. Loss: 0.3797287344932556. Accuracy: 80.9985\n",
      "Iteration: 110000. Loss: 0.41000956296920776. Accuracy: 80.932\n",
      "Iteration: 110500. Loss: 0.3819272518157959. Accuracy: 80.9245\n",
      "Iteration: 111000. Loss: 0.47906559705734253. Accuracy: 80.621\n",
      "Iteration: 111500. Loss: 0.41481485962867737. Accuracy: 80.958\n",
      "Iteration: 112000. Loss: 0.4131864905357361. Accuracy: 80.9975\n",
      "Iteration: 112500. Loss: 0.40232348442077637. Accuracy: 80.8615\n",
      "Iteration: 113000. Loss: 0.4521894156932831. Accuracy: 80.478\n",
      "Iteration: 113500. Loss: 0.4009134769439697. Accuracy: 81.0905\n",
      "Iteration: 114000. Loss: 0.3673189878463745. Accuracy: 80.9785\n",
      "Iteration: 114500. Loss: 0.39794665575027466. Accuracy: 81.148\n",
      "Iteration: 115000. Loss: 0.4457206428050995. Accuracy: 79.688\n",
      "Iteration: 115500. Loss: 0.4495619833469391. Accuracy: 80.8885\n",
      "Iteration: 116000. Loss: 0.46965405344963074. Accuracy: 80.784\n",
      "Iteration: 116500. Loss: 0.31065359711647034. Accuracy: 80.8325\n",
      "Iteration: 117000. Loss: 0.3801347017288208. Accuracy: 81.034\n",
      "Iteration: 117500. Loss: 0.37198472023010254. Accuracy: 81.089\n",
      "Iteration: 118000. Loss: 0.3511641323566437. Accuracy: 79.751\n",
      "Iteration: 118500. Loss: 0.5254541039466858. Accuracy: 80.864\n",
      "Iteration: 119000. Loss: 0.2790166139602661. Accuracy: 80.842\n",
      "Iteration: 119500. Loss: 0.43544670939445496. Accuracy: 80.914\n",
      "Iteration: 120000. Loss: 0.4115324318408966. Accuracy: 80.413\n",
      "Iteration: 120500. Loss: 0.46067237854003906. Accuracy: 80.964\n",
      "Iteration: 121000. Loss: 0.30198514461517334. Accuracy: 80.744\n",
      "Iteration: 121500. Loss: 0.35329174995422363. Accuracy: 81.249\n",
      "Iteration: 122000. Loss: 0.4078357219696045. Accuracy: 81.048\n",
      "Iteration: 122500. Loss: 0.3525138199329376. Accuracy: 81.099\n",
      "Iteration: 123000. Loss: 0.4663027822971344. Accuracy: 81.185\n",
      "Iteration: 123500. Loss: 0.5372320413589478. Accuracy: 81.075\n",
      "Iteration: 124000. Loss: 0.429046630859375. Accuracy: 80.5015\n",
      "Iteration: 124500. Loss: 0.38669508695602417. Accuracy: 81.133\n",
      "Iteration: 125000. Loss: 0.3961885869503021. Accuracy: 81.247\n",
      "Iteration: 125500. Loss: 0.3354399502277374. Accuracy: 81.323\n",
      "Iteration: 126000. Loss: 0.3808702230453491. Accuracy: 80.5685\n",
      "Iteration: 126500. Loss: 0.36218374967575073. Accuracy: 81.111\n",
      "Iteration: 127000. Loss: 0.38384243845939636. Accuracy: 80.883\n",
      "Iteration: 127500. Loss: 0.3626173436641693. Accuracy: 81.1425\n",
      "Iteration: 128000. Loss: 0.37572428584098816. Accuracy: 81.0665\n",
      "Iteration: 128500. Loss: 0.44909340143203735. Accuracy: 79.5735\n",
      "Iteration: 129000. Loss: 0.43368977308273315. Accuracy: 81.192\n",
      "Iteration: 129500. Loss: 0.3967598080635071. Accuracy: 81.07\n",
      "Iteration: 130000. Loss: 0.4013404846191406. Accuracy: 81.2995\n",
      "Iteration: 130500. Loss: 0.478224515914917. Accuracy: 80.897\n",
      "Iteration: 131000. Loss: 0.2918269634246826. Accuracy: 81.2505\n",
      "Iteration: 131500. Loss: 0.5186356902122498. Accuracy: 81.08\n",
      "Iteration: 132000. Loss: 0.48433902859687805. Accuracy: 81.283\n",
      "Iteration: 132500. Loss: 0.3876899778842926. Accuracy: 80.5875\n",
      "Iteration: 133000. Loss: 0.4886297285556793. Accuracy: 80.8165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 133500. Loss: 0.3756645917892456. Accuracy: 80.736\n",
      "Iteration: 134000. Loss: 0.41236329078674316. Accuracy: 81.1145\n",
      "Iteration: 134500. Loss: 0.29130420088768005. Accuracy: 80.8855\n",
      "Iteration: 135000. Loss: 0.4134744703769684. Accuracy: 81.358\n",
      "Iteration: 135500. Loss: 0.3195992708206177. Accuracy: 81.1705\n",
      "Iteration: 136000. Loss: 0.253841370344162. Accuracy: 81.079\n",
      "Iteration: 136500. Loss: 0.4218124449253082. Accuracy: 80.5195\n",
      "Iteration: 137000. Loss: 0.3713158369064331. Accuracy: 81.372\n",
      "Iteration: 137500. Loss: 0.48323681950569153. Accuracy: 80.3315\n",
      "Iteration: 138000. Loss: 0.3269413709640503. Accuracy: 81.1955\n",
      "Iteration: 138500. Loss: 0.5085546970367432. Accuracy: 81.27\n",
      "Iteration: 139000. Loss: 0.49210822582244873. Accuracy: 79.646\n",
      "Iteration: 139500. Loss: 0.3796399235725403. Accuracy: 80.6245\n",
      "Iteration: 140000. Loss: 0.4190775752067566. Accuracy: 81.323\n",
      "Iteration: 140500. Loss: 0.34134727716445923. Accuracy: 80.947\n",
      "Iteration: 141000. Loss: 0.4400840997695923. Accuracy: 81.0735\n",
      "Iteration: 141500. Loss: 0.23150292038917542. Accuracy: 81.022\n",
      "Iteration: 142000. Loss: 0.3597467839717865. Accuracy: 81.0815\n",
      "Iteration: 142500. Loss: 0.46718069911003113. Accuracy: 81.2535\n",
      "Iteration: 143000. Loss: 0.37319687008857727. Accuracy: 81.236\n",
      "Iteration: 143500. Loss: 0.32546523213386536. Accuracy: 81.3\n",
      "Iteration: 144000. Loss: 0.43674594163894653. Accuracy: 81.3045\n",
      "Iteration: 144500. Loss: 0.40141478180885315. Accuracy: 81.1645\n",
      "Iteration: 145000. Loss: 0.33882713317871094. Accuracy: 80.969\n",
      "Iteration: 145500. Loss: 0.4084920585155487. Accuracy: 81.2345\n",
      "Iteration: 146000. Loss: 0.38540539145469666. Accuracy: 81.0325\n",
      "Iteration: 146500. Loss: 0.46237051486968994. Accuracy: 80.981\n",
      "Iteration: 147000. Loss: 0.39927154779434204. Accuracy: 80.7265\n",
      "Iteration: 147500. Loss: 0.44414713978767395. Accuracy: 80.875\n",
      "Iteration: 148000. Loss: 0.4012744426727295. Accuracy: 81.174\n",
      "Iteration: 148500. Loss: 0.49068963527679443. Accuracy: 81.459\n",
      "Iteration: 149000. Loss: 0.3671337068080902. Accuracy: 81.304\n",
      "Iteration: 149500. Loss: 0.37047645449638367. Accuracy: 81.244\n",
      "Iteration: 150000. Loss: 0.40477442741394043. Accuracy: 80.5315\n",
      "Iteration: 150500. Loss: 0.35344263911247253. Accuracy: 81.014\n",
      "Iteration: 151000. Loss: 0.31806105375289917. Accuracy: 81.271\n",
      "Iteration: 151500. Loss: 0.4344400465488434. Accuracy: 81.052\n",
      "Iteration: 152000. Loss: 0.37336358428001404. Accuracy: 81.2265\n",
      "Iteration: 152500. Loss: 0.37422215938568115. Accuracy: 81.3885\n",
      "Iteration: 153000. Loss: 0.45093563199043274. Accuracy: 81.175\n",
      "Iteration: 153500. Loss: 0.42102211713790894. Accuracy: 81.2615\n",
      "Iteration: 154000. Loss: 0.3777167499065399. Accuracy: 81.0895\n",
      "Iteration: 154500. Loss: 0.44262340664863586. Accuracy: 80.7085\n",
      "Iteration: 155000. Loss: 0.4230116605758667. Accuracy: 80.68\n",
      "Iteration: 155500. Loss: 0.45965686440467834. Accuracy: 81.2985\n",
      "Iteration: 156000. Loss: 0.44076499342918396. Accuracy: 80.597\n",
      "Iteration: 156500. Loss: 0.45806702971458435. Accuracy: 81.2685\n",
      "Iteration: 157000. Loss: 0.5042516589164734. Accuracy: 81.3345\n",
      "Iteration: 157500. Loss: 0.4406224489212036. Accuracy: 81.498\n",
      "Iteration: 158000. Loss: 0.397991418838501. Accuracy: 81.373\n",
      "Iteration: 158500. Loss: 0.44647103548049927. Accuracy: 81.24\n",
      "Iteration: 159000. Loss: 0.3610766530036926. Accuracy: 81.2275\n",
      "Iteration: 159500. Loss: 0.49077361822128296. Accuracy: 81.4145\n",
      "Iteration: 160000. Loss: 0.4314568340778351. Accuracy: 81.433\n"
     ]
    }
   ],
   "source": [
    "iter = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs = torch.tensor(inputs).requires_grad_()\n",
    "        inputs = inputs.to(device)\n",
    "        # Load images with gradient accumulation capabilities\n",
    "        #images = images.view(-1, 28*28).requires_grad_()\n",
    "        labels = labels.to(device)\n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        iter += 1\n",
    "\n",
    "        if iter % 500 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for inputs, labels in test_loader:\n",
    "                inputs = torch.tensor(inputs).requires_grad_()\n",
    "                inputs = inputs.to(device)\n",
    "                # Load images with gradient accumulation capabilities\n",
    "                #images = images.view(-1, 28*28).requires_grad_()\n",
    "                labels = labels.to(device)\n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(inputs)\n",
    "\n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "\n",
    "                # Total correct predictions\n",
    "                correct += (predicted == labels).sum()\n",
    "\n",
    "            accuracy = 100 * float(correct) / float(total)\n",
    "\n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 hidden layer 50 unit, sigmoid act \n",
    "#Iteration: 82000. Loss: 0.5352512001991272. Accuracy: 68.227\n",
    "# 3 hidden layer 100 unit, sigmoid act \n",
    "#Iteration: 82500. Loss: 0.4631064236164093. Accuracy: 79.512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FeedforwardNeuralNetModel(\n",
      "  (fc1): Linear(in_features=7, out_features=100, bias=True)\n",
      "  (relu1): ReLU()\n",
      "  (fc2): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (relu2): ReLU()\n",
      "  (fc3): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (relu3): ReLU()\n",
      "  (fc4): Linear(in_features=100, out_features=2, bias=True)\n",
      "  (batch_norm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "## CovNet\n",
    "\n",
    "\n",
    "# defining the model\n",
    "covModel = CovNet()\n",
    "# defining the optimizer\n",
    "optimizer = torch.optim.Adam(covModel.parameters(), lr=0.07)\n",
    "# defining the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# checking if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "    \n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    tr_loss = 0\n",
    "    # getting the training set\n",
    "    x_train, y_train = torch.autograd.Variable(train_x), torch.autograd.Variable(train_y)\n",
    "    # getting the validation set\n",
    "    x_val, y_val = torch.autograd.Variable(val_x), torch.autograd.Variable(val_y)\n",
    "    # converting the data into GPU format\n",
    "    if torch.cuda.is_available():\n",
    "        x_train = x_train.cuda()\n",
    "        y_train = y_train.cuda()\n",
    "        x_val = x_val.cuda()\n",
    "        y_val = y_val.cuda()\n",
    "\n",
    "    # clearing the Gradients of the model parameters\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # prediction for training and validation set\n",
    "    output_train = model(x_train)\n",
    "    output_val = model(x_val)\n",
    "\n",
    "    # computing the training and validation loss\n",
    "    loss_train = criterion(output_train, y_train)\n",
    "    loss_val = criterion(output_val, y_val)\n",
    "    train_losses.append(loss_train)\n",
    "    val_losses.append(loss_val)\n",
    "\n",
    "    # computing the updated weights of all the model parameters\n",
    "    loss_train.backward()\n",
    "    optimizer.step()\n",
    "    tr_loss = loss_train.item()\n",
    "    if epoch%2 == 0:\n",
    "        # printing the validation loss\n",
    "        print('Epoch : ',epoch+1, '\\t', 'loss :', loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 dim 1 must match mat2 dim 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-128-4192b243c486>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# training the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-127-072bba51b12f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# prediction for training and validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0moutput_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0moutput_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch2/hle/py3_env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-101-7da63b0bd2c5>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;31m#out = self.dropout(out)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m#out = self.batch_norm(out)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch2/hle/py3_env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch2/hle/py3_env/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch2/hle/py3_env/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1672\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1673\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1674\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1675\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1676\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 dim 1 must match mat2 dim 0"
     ]
    }
   ],
   "source": [
    "train_x = torch.from_numpy(X_train)\n",
    "train_y = torch.from_numpy(np.array(y_train))\n",
    "val_x = torch.from_numpy(X_test)\n",
    "val_y = torch.from_numpy(np.array(y_test))\n",
    "# defining the number of epochs\n",
    "n_epochs = 10\n",
    "# empty list to store training losses\n",
    "train_losses = []\n",
    "# empty list to store validation losses\n",
    "val_losses = []\n",
    "# training the model\n",
    "for epoch in range(n_epochs):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel='rbf') # Linear Kernel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_X = X_train[:100000,:]\n",
    "chunk_Y = y_train[:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model using the training sets\n",
    "clf.fit(chunk_X, chunk_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_chunk = X_test[:40000,:]\n",
    "y_pred = clf.predict(X_test_chunk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200000"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.723625\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test[:40000], y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b7c5b39524a43c688ef5c225785c79b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65d0c9f9d391477cb166c756d5e3b444",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=569.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c957728f28c446097af2e3671911322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a28b5ee14e94718813ffa58faf212a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440514422.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at tbs17/MathBERT-custom were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"tbs17/MathBERT-custom\")\n",
    "\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"tbs17/MathBERT-custom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train model taking both inputs \n",
    "#combine short AND long.\n",
    "#histogram of data as input\n",
    "# polynomial SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
